{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing Theano\n",
    "# pip install --upgrade --no-deps git+git://github.com/Theano/Theano.git\n",
    "\n",
    "# Installing Tensorflow\n",
    "# pip install tensorflow\n",
    "\n",
    "# Installing Keras\n",
    "# pip install --upgrade keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## There is no data-pre processing involved here as we are dealing with images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 - Building the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:72: UserWarning: h5py is running against HDF5 1.10.2 when it was built against 1.10.3, this may cause problems\n",
      "  '{0}.{1}.{2}'.format(*version.hdf5_built_version_tuple)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "#The sequential library is used to initialize our neural network\n",
    "from keras.models import Sequential\n",
    "#since we are dealing with images and not videos and since images are 2D - we import the package Conv2D\n",
    "from keras.layers import Conv2D\n",
    "#As the name suggests Max Pooling is used for max-pooling\n",
    "from keras.layers import MaxPooling2D\n",
    "#Flatten package is used for flattening\n",
    "from keras.layers import Flatten\n",
    "#The dense library is used to build the layers of our ANN\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising the CNN\n",
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# Step 1 - Convolution\n",
    "# the first figure 32 refers to nb_filter or the number of feature detectors that we would be using. IT IS A PRACTICE TO ADD 32\n",
    "# FEATURE DETECTORS IN THE FIRST CONVOLUTIONAL LAYER.  The second and third layers could have 64 or 128 etc. \n",
    "# Also the 3,3 refers to the number of rows and columns in EACH feature detector. \n",
    "# The input shape number ordering will differ based on wether you are using theano backend or tensorflow backend.  If you are \n",
    "# using theano then it would be input_shape = (3, 64, 64) where 3 corresponds to wether it is a colored image - 3 color channels \n",
    "# of RGB.  For a Black and white image it would be 1 as there is only 1 channel and 64, 64 refers to the number of pixels.  If you have larger processing capabilities or if you are using GPUs then you\n",
    "# could mention it as 256, 256 or 1088,1088.  Here since we are using tensorflow backend the order is changed to 64, 64, 3.  \n",
    "# The activation function relu here in this context is used to remove negative pixels - so as to eliminate non-linearity\n",
    "classifier.add(Conv2D(32, (3, 3), input_shape = (64, 64, 3), activation = 'relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2 - Pooling\n",
    "# Here in max pooling we scan the feature map in a 2x2 sub-set to create a pooled feature map\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a second convolutional layer\n",
    "#the second hidden layer does not face the input layer as it faces the first hidden layer.  Therefore the input_shape is not given\n",
    "# This would work on the pooled feature maps which are output from the previous step. \n",
    "# Also for greater performance you can double the number of convolutional feature detectors from 32 to 64.  If you decide to \n",
    "# add one more layer then you can further double it from 64 to 128.  But now here - we decide to keep it at 32 only and not \n",
    "# double it. \n",
    "classifier.add(Conv2D(32, (3, 3), activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3 - Flattening\n",
    "classifier.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4 - Full connection\n",
    "# here in the first layer we choose the number of nodes randomly that is not too small or large.  So 128 is something optimal. \n",
    "# Also we use relu as activation function.  In the next layer we just have one node required - which indicates the probability\n",
    "# of it being a cat or dog.  So we choose 1 unit and a sigmoid activation function. Here instead of units we can also use the term\n",
    "# output_dim\n",
    "classifier.add(Dense(units = 128, activation = 'relu'))\n",
    "classifier.add(Dense(units = 1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the CNN\n",
    "# Optimizer is the algorithm you would use to find the optimal set of weights.  There are different types of stochastic gradient\n",
    "# descent algorithms.  One of the most efficient one is the adam algorithm\n",
    "# Loss refers to the loss function within the stochastic gradient descent adam algorithm. If the predicted label has two outcomes\n",
    "# then the loss function used is binary_crossentropy.  If there are more than two then it is categorical_crossentropy.\n",
    "# For metrics here we are going to use accuracy as a measurement to see how well the algorithm is performing\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 - Fitting the CNN to the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The next two steps have to do with image augmentation - which would remove the possibility of over-fitting our model and improve\n",
    "#the model performance on the test set\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normally pixels take values from 0 to 255.  So in the first step we rescale that value to be between 0 and 1\n",
    "#shear_range and zoom_range are random transformations that we do to the image.  0.2 indicates the extant to which we do those\n",
    "#transformations.  Also our images would be flipped horizontally. So all these are done so that we don't end up having\n",
    "#the same image in different batches of training. \n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#It is important to prepare the dataset folder.  You should have two sub-folders called 'training_set' and 'test_set' and all the\n",
    "#images should be there.\n",
    "#Again within the training set - if you want to label your images - then create another sub-folder with that name and put all the \n",
    "#images into that. For eg. like dog or cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#'C:/old d drive/New folder/Data Science/Udemy ML A to Z/Convolutional_Neural_Networks/dataset/training_set'\n",
    "#training_set = train_datagen.flow_from_directory('dataset/training_set',\n",
    "#target_size is the size of the images that we expect in the CNN model.  We are considering 64x64 dimensions for our images\n",
    "#batch_size indicates the number of random images that would be passed into the CNN to do the training. Here we give 32 images\n",
    "#at a time.  Class_mode is a parameter that indicates wether the label/predicted variable has more than two values.  Here we have\n",
    "#only two values : cat and dog. \n",
    "training_set = train_datagen.flow_from_directory('C:/old d drive/New folder/Data Science/Udemy ML A to Z/Convolutional_Neural_Networks/dataset/training_set',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#test_set = test_datagen.flow_from_directory('dataset/test_set',\n",
    "test_set = test_datagen.flow_from_directory('C:/old d drive/New folder/Data Science/Udemy ML A to Z/Convolutional_Neural_Networks/dataset/training_set',\n",
    "                                            target_size = (64, 64),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/25\n",
      "7999/8000 [============================>.] - ETA: 0s - loss: 0.3341 - acc: 0.8410"
     ]
    }
   ],
   "source": [
    "#steps_per_epoch indicates the number of images we have in our training set\n",
    "classifier.fit_generator(training_set,\n",
    "                         steps_per_epoch = 8000,\n",
    "                         epochs = 25,\n",
    "                         validation_data = test_set,\n",
    "                         validation_steps = 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
